nohup: ignoring input
A的第二大特征值: 1.0
A的beta: 0.7875559944177453
A的spectral gap: 0.21244400558225474
A的kappa: 2.63054187192118
S_A是: 55.558824204811295 

(9, 9)
使用异质性数据集
函数内设置种子为: 2
root: /home/lg/ICML2025_project/PUSHPULL_PROJECT/最终的实验/grid_mnist_tmp
使用 PushPull 算法, 这里只记录grad_nrom
直接从第一次 closure() 调用中获取初始值
Initial grad norm: 0.008754083938482735, Initial avg grad norm: 0.00285701802931726
optimizer初始化成功!
Training Progress:   0%|          | 0/2000 [00:00<?, ?it/s]/home/lg/ICML2025_project/utils/train_utils.py:210: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
Training Progress:   0%|          | 0/2000 [00:02<?, ?it/s, epoch=1, test_accuracy=11.1100%, test_loss=2.2948, train_loss=1.1014]Training Progress:   0%|          | 1/2000 [00:02<1:39:15,  2.98s/it, epoch=1, test_accuracy=11.1100%, test_loss=2.2948, train_loss=1.1014]Training Progress:   0%|          | 1/2000 [00:05<1:39:15,  2.98s/it, epoch=2, test_accuracy=11.6500%, test_loss=2.2804, train_loss=1.0924]Training Progress:   0%|          | 2/2000 [00:05<1:32:02,  2.76s/it, epoch=2, test_accuracy=11.6500%, test_loss=2.2804, train_loss=1.0924]Training Progress:   0%|          | 2/2000 [00:08<1:32:02,  2.76s/it, epoch=3, test_accuracy=12.7100%, test_loss=2.2659, train_loss=1.0821]Training Progress:   0%|          | 3/2000 [00:08<1:30:26,  2.72s/it, epoch=3, test_accuracy=12.7100%, test_loss=2.2659, train_loss=1.0821]Training Progress:   0%|          | 3/2000 [00:11<1:30:26,  2.72s/it, epoch=4, test_accuracy=13.9000%, test_loss=2.2511, train_loss=1.0721]Training Progress:   0%|          | 4/2000 [00:11<1:32:04,  2.77s/it, epoch=4, test_accuracy=13.9000%, test_loss=2.2511, train_loss=1.0721]Training Progress:   0%|          | 4/2000 [00:14<1:32:04,  2.77s/it, epoch=5, test_accuracy=15.2900%, test_loss=2.2356, train_loss=1.0618]Training Progress:   0%|          | 5/2000 [00:14<1:35:12,  2.86s/it, epoch=5, test_accuracy=15.2900%, test_loss=2.2356, train_loss=1.0618]Training Progress:   0%|          | 5/2000 [00:16<1:35:12,  2.86s/it, epoch=6, test_accuracy=17.2500%, test_loss=2.2192, train_loss=1.0504]Training Progress:   0%|          | 6/2000 [00:16<1:33:30,  2.81s/it, epoch=6, test_accuracy=17.2500%, test_loss=2.2192, train_loss=1.0504]Training Progress:   0%|          | 6/2000 [00:19<1:33:30,  2.81s/it, epoch=7, test_accuracy=20.7900%, test_loss=2.2019, train_loss=1.0398]Training Progress:   0%|          | 7/2000 [00:19<1:32:46,  2.79s/it, epoch=7, test_accuracy=20.7900%, test_loss=2.2019, train_loss=1.0398]Training Progress:   0%|          | 7/2000 [00:22<1:32:46,  2.79s/it, epoch=8, test_accuracy=24.0900%, test_loss=2.1829, train_loss=1.0277]Training Progress:   0%|          | 8/2000 [00:22<1:30:19,  2.72s/it, epoch=8, test_accuracy=24.0900%, test_loss=2.1829, train_loss=1.0277]Training Progress:   0%|          | 8/2000 [00:24<1:30:19,  2.72s/it, epoch=9, test_accuracy=28.0900%, test_loss=2.1620, train_loss=1.0150]Training Progress:   0%|          | 9/2000 [00:24<1:30:42,  2.73s/it, epoch=9, test_accuracy=28.0900%, test_loss=2.1620, train_loss=1.0150]Training Progress:   0%|          | 9/2000 [00:27<1:30:42,  2.73s/it, epoch=10, test_accuracy=31.8100%, test_loss=2.1393, train_loss=1.0014]Training Progress:   0%|          | 10/2000 [00:27<1:32:00,  2.77s/it, epoch=10, test_accuracy=31.8100%, test_loss=2.1393, train_loss=1.0014]Training Progress:   0%|          | 10/2000 [00:30<1:32:00,  2.77s/it, epoch=11, test_accuracy=35.4700%, test_loss=2.1138, train_loss=0.9866]Training Progress:   1%|          | 11/2000 [00:30<1:30:50,  2.74s/it, epoch=11, test_accuracy=35.4700%, test_loss=2.1138, train_loss=0.9866]Training Progress:   1%|          | 11/2000 [00:33<1:30:50,  2.74s/it, epoch=12, test_accuracy=39.4500%, test_loss=2.0854, train_loss=0.9708]Training Progress:   1%|          | 12/2000 [00:33<1:28:55,  2.68s/it, epoch=12, test_accuracy=39.4500%, test_loss=2.0854, train_loss=0.9708]Training Progress:   1%|          | 12/2000 [00:35<1:28:55,  2.68s/it, epoch=13, test_accuracy=43.4800%, test_loss=2.0541, train_loss=0.9533]Training Progress:   1%|          | 13/2000 [00:35<1:29:52,  2.71s/it, epoch=13, test_accuracy=43.4800%, test_loss=2.0541, train_loss=0.9533]Training Progress:   1%|          | 13/2000 [00:38<1:29:52,  2.71s/it, epoch=14, test_accuracy=47.6800%, test_loss=2.0194, train_loss=0.9351]Training Progress:   1%|          | 14/2000 [00:38<1:30:51,  2.75s/it, epoch=14, test_accuracy=47.6800%, test_loss=2.0194, train_loss=0.9351]Training Progress:   1%|          | 14/2000 [00:41<1:30:51,  2.75s/it, epoch=15, test_accuracy=51.4800%, test_loss=1.9812, train_loss=0.9156]Training Progress:   1%|          | 15/2000 [00:41<1:33:21,  2.82s/it, epoch=15, test_accuracy=51.4800%, test_loss=1.9812, train_loss=0.9156]Training Progress:   1%|          | 15/2000 [00:44<1:33:21,  2.82s/it, epoch=16, test_accuracy=54.4700%, test_loss=1.9396, train_loss=0.8920]Training Progress:   1%|          | 16/2000 [00:44<1:30:12,  2.73s/it, epoch=16, test_accuracy=54.4700%, test_loss=1.9396, train_loss=0.8920]Training Progress:   1%|          | 16/2000 [00:46<1:30:12,  2.73s/it, epoch=17, test_accuracy=56.9400%, test_loss=1.8941, train_loss=0.8684]Training Progress:   1%|          | 17/2000 [00:46<1:28:45,  2.69s/it, epoch=17, test_accuracy=56.9400%, test_loss=1.8941, train_loss=0.8684]