nohup: ignoring input
A的第二大特征值: 0.40034491106851067
A的beta: 0.908470776991466
A的spectral gap: 0.09152922300853406
A的kappa: 4.461208641078092
S_A是: 272.63639338924634 

(25, 25)
使用异质性数据集
函数内设置种子为: 2
root: /home/lg/ICML2025_project/PUSHPULL_PROJECT/最终的实验/grid_mnist_tmp
使用 PushPull 算法, 这里只记录grad_nrom
直接从第一次 closure() 调用中获取初始值
Initial grad norm: 0.009343492332845926, Initial avg grad norm: 0.001722550019621849
optimizer初始化成功!
Training Progress:   0%|          | 0/6000 [00:00<?, ?it/s]/home/lg/ICML2025_project/utils/train_utils.py:210: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
Training Progress:   0%|          | 0/6000 [00:02<?, ?it/s, epoch=1, test_accuracy=9.9700%, test_loss=2.3024, train_loss=0.8914]Training Progress:   0%|          | 1/6000 [00:02<3:43:16,  2.23s/it, epoch=1, test_accuracy=9.9700%, test_loss=2.3024, train_loss=0.8914]Training Progress:   0%|          | 1/6000 [00:04<3:43:16,  2.23s/it, epoch=2, test_accuracy=10.7300%, test_loss=2.3018, train_loss=0.8948]Training Progress:   0%|          | 2/6000 [00:04<3:52:44,  2.33s/it, epoch=2, test_accuracy=10.7300%, test_loss=2.3018, train_loss=0.8948]Training Progress:   0%|          | 2/6000 [00:07<3:52:44,  2.33s/it, epoch=3, test_accuracy=12.3200%, test_loss=2.3012, train_loss=0.8947]Training Progress:   0%|          | 3/6000 [00:07<4:02:34,  2.43s/it, epoch=3, test_accuracy=12.3200%, test_loss=2.3012, train_loss=0.8947]Training Progress:   0%|          | 3/6000 [00:09<4:02:34,  2.43s/it, epoch=4, test_accuracy=14.5500%, test_loss=2.3005, train_loss=0.8945]Training Progress:   0%|          | 4/6000 [00:09<3:58:07,  2.38s/it, epoch=4, test_accuracy=14.5500%, test_loss=2.3005, train_loss=0.8945]Training Progress:   0%|          | 4/6000 [00:11<3:58:07,  2.38s/it, epoch=5, test_accuracy=17.0600%, test_loss=2.2999, train_loss=0.8942]Training Progress:   0%|          | 5/6000 [00:11<4:02:15,  2.42s/it, epoch=5, test_accuracy=17.0600%, test_loss=2.2999, train_loss=0.8942]Training Progress:   0%|          | 5/6000 [00:14<4:02:15,  2.42s/it, epoch=6, test_accuracy=19.6700%, test_loss=2.2992, train_loss=0.8939]Training Progress:   0%|          | 6/6000 [00:14<4:00:00,  2.40s/it, epoch=6, test_accuracy=19.6700%, test_loss=2.2992, train_loss=0.8939]Training Progress:   0%|          | 6/6000 [00:17<4:00:00,  2.40s/it, epoch=7, test_accuracy=22.1700%, test_loss=2.2985, train_loss=0.8936]Training Progress:   0%|          | 7/6000 [00:17<4:10:05,  2.50s/it, epoch=7, test_accuracy=22.1700%, test_loss=2.2985, train_loss=0.8936]Training Progress:   0%|          | 7/6000 [00:19<4:10:05,  2.50s/it, epoch=8, test_accuracy=24.6600%, test_loss=2.2978, train_loss=0.8933]Training Progress:   0%|          | 8/6000 [00:19<4:07:10,  2.48s/it, epoch=8, test_accuracy=24.6600%, test_loss=2.2978, train_loss=0.8933]Training Progress:   0%|          | 8/6000 [00:21<4:07:10,  2.48s/it, epoch=9, test_accuracy=27.3500%, test_loss=2.2972, train_loss=0.8930]Training Progress:   0%|          | 9/6000 [00:21<4:07:20,  2.48s/it, epoch=9, test_accuracy=27.3500%, test_loss=2.2972, train_loss=0.8930]Training Progress:   0%|          | 9/6000 [00:24<4:07:20,  2.48s/it, epoch=10, test_accuracy=29.7000%, test_loss=2.2965, train_loss=0.8927]Training Progress:   0%|          | 10/6000 [00:24<4:10:11,  2.51s/it, epoch=10, test_accuracy=29.7000%, test_loss=2.2965, train_loss=0.8927]Training Progress:   0%|          | 10/6000 [00:27<4:10:11,  2.51s/it, epoch=11, test_accuracy=31.4100%, test_loss=2.2958, train_loss=0.8924]Training Progress:   0%|          | 11/6000 [00:27<4:17:45,  2.58s/it, epoch=11, test_accuracy=31.4100%, test_loss=2.2958, train_loss=0.8924]Training Progress:   0%|          | 11/6000 [00:29<4:17:45,  2.58s/it, epoch=12, test_accuracy=32.8900%, test_loss=2.2952, train_loss=0.8921]Training Progress:   0%|          | 12/6000 [00:29<4:19:27,  2.60s/it, epoch=12, test_accuracy=32.8900%, test_loss=2.2952, train_loss=0.8921]Training Progress:   0%|          | 12/6000 [00:32<4:19:27,  2.60s/it, epoch=13, test_accuracy=34.1800%, test_loss=2.2945, train_loss=0.8918]Training Progress:   0%|          | 13/6000 [00:32<4:19:06,  2.60s/it, epoch=13, test_accuracy=34.1800%, test_loss=2.2945, train_loss=0.8918]Training Progress:   0%|          | 13/6000 [00:35<4:19:06,  2.60s/it, epoch=14, test_accuracy=35.3700%, test_loss=2.2938, train_loss=0.8916]Training Progress:   0%|          | 14/6000 [00:35<4:23:07,  2.64s/it, epoch=14, test_accuracy=35.3700%, test_loss=2.2938, train_loss=0.8916]Training Progress:   0%|          | 14/6000 [00:38<4:23:07,  2.64s/it, epoch=15, test_accuracy=36.2000%, test_loss=2.2931, train_loss=0.8912]Training Progress:   0%|          | 15/6000 [00:38<4:30:44,  2.71s/it, epoch=15, test_accuracy=36.2000%, test_loss=2.2931, train_loss=0.8912]Training Progress:   0%|          | 15/6000 [00:40<4:30:44,  2.71s/it, epoch=16, test_accuracy=37.0000%, test_loss=2.2924, train_loss=0.8908]Training Progress:   0%|          | 16/6000 [00:40<4:27:17,  2.68s/it, epoch=16, test_accuracy=37.0000%, test_loss=2.2924, train_loss=0.8908]Training Progress:   0%|          | 16/6000 [00:43<4:27:17,  2.68s/it, epoch=17, test_accuracy=37.4700%, test_loss=2.2917, train_loss=0.8906]Training Progress:   0%|          | 17/6000 [00:43<4:21:45,  2.63s/it, epoch=17, test_accuracy=37.4700%, test_loss=2.2917, train_loss=0.8906]Training Progress:   0%|          | 17/6000 [00:45<4:21:45,  2.63s/it, epoch=18, test_accuracy=38.1900%, test_loss=2.2910, train_loss=0.8903]Training Progress:   0%|          | 18/6000 [00:45<4:20:13,  2.61s/it, epoch=18, test_accuracy=38.1900%, test_loss=2.2910, train_loss=0.8903]Training Progress:   0%|          | 18/6000 [00:48<4:20:13,  2.61s/it, epoch=19, test_accuracy=38.8500%, test_loss=2.2903, train_loss=0.8899]Training Progress:   0%|          | 19/6000 [00:48<4:22:21,  2.63s/it, epoch=19, test_accuracy=38.8500%, test_loss=2.2903, train_loss=0.8899]Training Progress:   0%|          | 19/6000 [00:51<4:22:21,  2.63s/it, epoch=20, test_accuracy=39.3400%, test_loss=2.2896, train_loss=0.8897]Training Progress:   0%|          | 20/6000 [00:51<4:26:58,  2.68s/it, epoch=20, test_accuracy=39.3400%, test_loss=2.2896, train_loss=0.8897]Training Progress:   0%|          | 20/6000 [00:53<4:26:58,  2.68s/it, epoch=21, test_accuracy=39.6000%, test_loss=2.2888, train_loss=0.8893]Training Progress:   0%|          | 21/6000 [00:53<4:26:13,  2.67s/it, epoch=21, test_accuracy=39.6000%, test_loss=2.2888, train_loss=0.8893]Training Progress:   0%|          | 21/6000 [00:56<4:26:13,  2.67s/it, epoch=22, test_accuracy=39.9000%, test_loss=2.2881, train_loss=0.8890]Training Progress:   0%|          | 22/6000 [00:56<4:28:27,  2.69s/it, epoch=22, test_accuracy=39.9000%, test_loss=2.2881, train_loss=0.8890]