nohup: ignoring input
A的第二大特征值: 0.7294502564570327
A的beta: 0.7329446997891795
A的spectral gap: 0.26705530021082047
A的kappa: 3.519346933904817
S_A是: 58.58633474618187 

(12, 12)
使用异质性数据集
函数内设置种子为: 2
root: /home/lg/ICML2025_project/PUSHPULL_PROJECT/最终的实验/geometric_tmp
使用 PushPull 算法, 这里只记录grad_nrom
直接从第一次 closure() 调用中获取初始值
Initial grad norm: 0.010107412856693069, Initial avg grad norm: 0.0026587843894958496
optimizer初始化成功!
Training Progress:   0%|          | 0/1000 [00:00<?, ?it/s]/home/lg/ICML2025_project/utils/train_utils.py:210: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
Training Progress:   0%|          | 0/1000 [00:03<?, ?it/s, epoch=1, test_accuracy=25.1400%, test_loss=2.2911, train_loss=1.1159]Training Progress:   0%|          | 1/1000 [00:03<50:07,  3.01s/it, epoch=1, test_accuracy=25.1400%, test_loss=2.2911, train_loss=1.1159]Training Progress:   0%|          | 1/1000 [00:05<50:07,  3.01s/it, epoch=2, test_accuracy=35.5500%, test_loss=2.2730, train_loss=1.1056]Training Progress:   0%|          | 2/1000 [00:05<47:15,  2.84s/it, epoch=2, test_accuracy=35.5500%, test_loss=2.2730, train_loss=1.1056]Training Progress:   0%|          | 2/1000 [00:08<47:15,  2.84s/it, epoch=3, test_accuracy=39.2400%, test_loss=2.2536, train_loss=1.0939]Training Progress:   0%|          | 3/1000 [00:08<45:05,  2.71s/it, epoch=3, test_accuracy=39.2400%, test_loss=2.2536, train_loss=1.0939]Training Progress:   0%|          | 3/1000 [00:10<45:05,  2.71s/it, epoch=4, test_accuracy=40.9800%, test_loss=2.2319, train_loss=1.0817]Training Progress:   0%|          | 4/1000 [00:10<44:14,  2.66s/it, epoch=4, test_accuracy=40.9800%, test_loss=2.2319, train_loss=1.0817]Training Progress:   0%|          | 4/1000 [00:13<44:14,  2.66s/it, epoch=5, test_accuracy=42.1300%, test_loss=2.2069, train_loss=1.0676]Training Progress:   0%|          | 5/1000 [00:13<43:50,  2.64s/it, epoch=5, test_accuracy=42.1300%, test_loss=2.2069, train_loss=1.0676]Training Progress:   0%|          | 5/1000 [00:16<43:50,  2.64s/it, epoch=6, test_accuracy=43.8500%, test_loss=2.1768, train_loss=1.0508]Training Progress:   1%|          | 6/1000 [00:16<43:19,  2.61s/it, epoch=6, test_accuracy=43.8500%, test_loss=2.1768, train_loss=1.0508]Training Progress:   1%|          | 6/1000 [00:18<43:19,  2.61s/it, epoch=7, test_accuracy=45.0600%, test_loss=2.1406, train_loss=1.0315]Training Progress:   1%|          | 7/1000 [00:18<43:37,  2.64s/it, epoch=7, test_accuracy=45.0600%, test_loss=2.1406, train_loss=1.0315]Training Progress:   1%|          | 7/1000 [00:21<43:37,  2.64s/it, epoch=8, test_accuracy=46.1600%, test_loss=2.0963, train_loss=1.0090]Training Progress:   1%|          | 8/1000 [00:21<44:54,  2.72s/it, epoch=8, test_accuracy=46.1600%, test_loss=2.0963, train_loss=1.0090]Training Progress:   1%|          | 8/1000 [00:24<44:54,  2.72s/it, epoch=9, test_accuracy=48.1600%, test_loss=2.0424, train_loss=0.9820]Training Progress:   1%|          | 9/1000 [00:24<45:40,  2.77s/it, epoch=9, test_accuracy=48.1600%, test_loss=2.0424, train_loss=0.9820]Training Progress:   1%|          | 9/1000 [00:27<45:40,  2.77s/it, epoch=10, test_accuracy=50.0800%, test_loss=1.9773, train_loss=0.9489]Training Progress:   1%|          | 10/1000 [00:27<45:08,  2.74s/it, epoch=10, test_accuracy=50.0800%, test_loss=1.9773, train_loss=0.9489]Training Progress:   1%|          | 10/1000 [00:30<45:08,  2.74s/it, epoch=11, test_accuracy=51.7900%, test_loss=1.9005, train_loss=0.9075]Training Progress:   1%|          | 11/1000 [00:30<47:12,  2.86s/it, epoch=11, test_accuracy=51.7900%, test_loss=1.9005, train_loss=0.9075]Training Progress:   1%|          | 11/1000 [00:33<47:12,  2.86s/it, epoch=12, test_accuracy=52.8500%, test_loss=1.8132, train_loss=0.8647]Training Progress:   1%|          | 12/1000 [00:33<50:15,  3.05s/it, epoch=12, test_accuracy=52.8500%, test_loss=1.8132, train_loss=0.8647]Training Progress:   1%|          | 12/1000 [00:37<50:15,  3.05s/it, epoch=13, test_accuracy=54.8300%, test_loss=1.7173, train_loss=0.8157]Training Progress:   1%|▏         | 13/1000 [00:37<51:58,  3.16s/it, epoch=13, test_accuracy=54.8300%, test_loss=1.7173, train_loss=0.8157]Training Progress:   1%|▏         | 13/1000 [00:40<51:58,  3.16s/it, epoch=14, test_accuracy=57.0700%, test_loss=1.6168, train_loss=0.7652]Training Progress:   1%|▏         | 14/1000 [00:40<52:20,  3.19s/it, epoch=14, test_accuracy=57.0700%, test_loss=1.6168, train_loss=0.7652]Training Progress:   1%|▏         | 14/1000 [00:43<52:20,  3.19s/it, epoch=15, test_accuracy=59.2500%, test_loss=1.5169, train_loss=0.7140]Training Progress:   2%|▏         | 15/1000 [00:43<52:54,  3.22s/it, epoch=15, test_accuracy=59.2500%, test_loss=1.5169, train_loss=0.7140]Training Progress:   2%|▏         | 15/1000 [00:47<52:54,  3.22s/it, epoch=16, test_accuracy=62.1900%, test_loss=1.4195, train_loss=0.6607]Training Progress:   2%|▏         | 16/1000 [00:47<53:58,  3.29s/it, epoch=16, test_accuracy=62.1900%, test_loss=1.4195, train_loss=0.6607]Training Progress:   2%|▏         | 16/1000 [00:50<53:58,  3.29s/it, epoch=17, test_accuracy=64.7300%, test_loss=1.3268, train_loss=0.6163]Training Progress:   2%|▏         | 17/1000 [00:50<54:28,  3.32s/it, epoch=17, test_accuracy=64.7300%, test_loss=1.3268, train_loss=0.6163]Training Progress:   2%|▏         | 17/1000 [00:53<54:28,  3.32s/it, epoch=18, test_accuracy=67.4800%, test_loss=1.2404, train_loss=0.5731]Training Progress:   2%|▏         | 18/1000 [00:53<54:38,  3.34s/it, epoch=18, test_accuracy=67.4800%, test_loss=1.2404, train_loss=0.5731]Training Progress:   2%|▏         | 18/1000 [00:57<54:38,  3.34s/it, epoch=19, test_accuracy=69.5300%, test_loss=1.1608, train_loss=0.5343]Training Progress:   2%|▏         | 19/1000 [00:57<54:44,  3.35s/it, epoch=19, test_accuracy=69.5300%, test_loss=1.1608, train_loss=0.5343]Training Progress:   2%|▏         | 19/1000 [01:00<54:44,  3.35s/it, epoch=20, test_accuracy=70.8000%, test_loss=1.0907, train_loss=0.4992]Training Progress:   2%|▏         | 20/1000 [01:00<55:34,  3.40s/it, epoch=20, test_accuracy=70.8000%, test_loss=1.0907, train_loss=0.4992]Training Progress:   2%|▏         | 20/1000 [01:04<55:34,  3.40s/it, epoch=21, test_accuracy=72.4700%, test_loss=1.0272, train_loss=0.4664]Training Progress:   2%|▏         | 21/1000 [01:04<54:49,  3.36s/it, epoch=21, test_accuracy=72.4700%, test_loss=1.0272, train_loss=0.4664]Training Progress:   2%|▏         | 21/1000 [01:07<54:49,  3.36s/it, epoch=22, test_accuracy=73.4500%, test_loss=0.9686, train_loss=0.4412]Training Progress:   2%|▏         | 22/1000 [01:07<54:06,  3.32s/it, epoch=22, test_accuracy=73.4500%, test_loss=0.9686, train_loss=0.4412]Training Progress:   2%|▏         | 22/1000 [01:10<54:06,  3.32s/it, epoch=23, test_accuracy=74.5400%, test_loss=0.9173, train_loss=0.4178]Training Progress:   2%|▏         | 23/1000 [01:10<52:58,  3.25s/it, epoch=23, test_accuracy=74.5400%, test_loss=0.9173, train_loss=0.4178]Training Progress:   2%|▏         | 23/1000 [01:13<52:58,  3.25s/it, epoch=24, test_accuracy=75.1500%, test_loss=0.8699, train_loss=0.3968]Training Progress:   2%|▏         | 24/1000 [01:13<52:33,  3.23s/it, epoch=24, test_accuracy=75.1500%, test_loss=0.8699, train_loss=0.3968]Training Progress:   2%|▏         | 24/1000 [01:16<52:33,  3.23s/it, epoch=25, test_accuracy=75.7400%, test_loss=0.8287, train_loss=0.3773]Training Progress:   2%|▎         | 25/1000 [01:16<52:12,  3.21s/it, epoch=25, test_accuracy=75.7400%, test_loss=0.8287, train_loss=0.3773]Training Progress:   2%|▎         | 25/1000 [01:20<52:12,  3.21s/it, epoch=26, test_accuracy=76.5500%, test_loss=0.7915, train_loss=0.3596]Training Progress:   3%|▎         | 26/1000 [01:20<52:38,  3.24s/it, epoch=26, test_accuracy=76.5500%, test_loss=0.7915, train_loss=0.3596]Training Progress:   3%|▎         | 26/1000 [01:23<52:38,  3.24s/it, epoch=27, test_accuracy=77.3500%, test_loss=0.7598, train_loss=0.3469]Training Progress:   3%|▎         | 27/1000 [01:23<54:06,  3.34s/it, epoch=27, test_accuracy=77.3500%, test_loss=0.7598, train_loss=0.3469]Training Progress:   3%|▎         | 27/1000 [01:27<54:06,  3.34s/it, epoch=28, test_accuracy=77.9600%, test_loss=0.7301, train_loss=0.3314]Training Progress:   3%|▎         | 28/1000 [01:27<54:48,  3.38s/it, epoch=28, test_accuracy=77.9600%, test_loss=0.7301, train_loss=0.3314]Training Progress:   3%|▎         | 28/1000 [01:30<54:48,  3.38s/it, epoch=29, test_accuracy=78.6800%, test_loss=0.7012, train_loss=0.3183]Training Progress:   3%|▎         | 29/1000 [01:30<55:24,  3.42s/it, epoch=29, test_accuracy=78.6800%, test_loss=0.7012, train_loss=0.3183]Training Progress:   3%|▎         | 29/1000 [01:34<55:24,  3.42s/it, epoch=30, test_accuracy=79.1000%, test_loss=0.6798, train_loss=0.3061]Training Progress:   3%|▎         | 30/1000 [01:34<55:49,  3.45s/it, epoch=30, test_accuracy=79.1000%, test_loss=0.6798, train_loss=0.3061]Training Progress:   3%|▎         | 30/1000 [01:38<55:49,  3.45s/it, epoch=31, test_accuracy=80.2400%, test_loss=0.6551, train_loss=0.2994]Training Progress:   3%|▎         | 31/1000 [01:38<58:25,  3.62s/it, epoch=31, test_accuracy=80.2400%, test_loss=0.6551, train_loss=0.2994]Training Progress:   3%|▎         | 31/1000 [01:42<58:25,  3.62s/it, epoch=32, test_accuracy=81.3700%, test_loss=0.6342, train_loss=0.2885]Training Progress:   3%|▎         | 32/1000 [01:42<1:00:15,  3.74s/it, epoch=32, test_accuracy=81.3700%, test_loss=0.6342, train_loss=0.2885]Training Progress:   3%|▎         | 32/1000 [01:46<1:00:15,  3.74s/it, epoch=33, test_accuracy=81.9200%, test_loss=0.6161, train_loss=0.2801]Training Progress:   3%|▎         | 33/1000 [01:46<1:01:27,  3.81s/it, epoch=33, test_accuracy=81.9200%, test_loss=0.6161, train_loss=0.2801]Training Progress:   3%|▎         | 33/1000 [01:50<1:01:27,  3.81s/it, epoch=34, test_accuracy=82.5300%, test_loss=0.5990, train_loss=0.2718]Training Progress:   3%|▎         | 34/1000 [01:50<1:02:35,  3.89s/it, epoch=34, test_accuracy=82.5300%, test_loss=0.5990, train_loss=0.2718]Training Progress:   3%|▎         | 34/1000 [01:54<1:02:35,  3.89s/it, epoch=35, test_accuracy=83.1200%, test_loss=0.5826, train_loss=0.2643]Training Progress:   4%|▎         | 35/1000 [01:54<1:02:37,  3.89s/it, epoch=35, test_accuracy=83.1200%, test_loss=0.5826, train_loss=0.2643]Training Progress:   4%|▎         | 35/1000 [01:58<1:02:37,  3.89s/it, epoch=36, test_accuracy=83.4700%, test_loss=0.5685, train_loss=0.2563]Training Progress:   4%|▎         | 36/1000 [01:58<1:02:35,  3.90s/it, epoch=36, test_accuracy=83.4700%, test_loss=0.5685, train_loss=0.2563]Training Progress:   4%|▎         | 36/1000 [02:02<1:02:35,  3.90s/it, epoch=37, test_accuracy=84.1600%, test_loss=0.5539, train_loss=0.2526]Training Progress:   4%|▎         | 37/1000 [02:02<1:03:02,  3.93s/it, epoch=37, test_accuracy=84.1600%, test_loss=0.5539, train_loss=0.2526]Training Progress:   4%|▎         | 37/1000 [02:06<1:03:02,  3.93s/it, epoch=38, test_accuracy=84.5000%, test_loss=0.5423, train_loss=0.2451]Training Progress:   4%|▍         | 38/1000 [02:06<1:03:52,  3.98s/it, epoch=38, test_accuracy=84.5000%, test_loss=0.5423, train_loss=0.2451]