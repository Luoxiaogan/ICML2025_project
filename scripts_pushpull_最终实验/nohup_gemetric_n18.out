nohup: ignoring input
A的第二大特征值: 0.6899624881743293
A的beta: 0.7066374584043071
A的spectral gap: 0.29336254159569286
A的kappa: 4.86720846275085
S_A是: 74.69738127621541 

(18, 18)
使用异质性数据集
函数内设置种子为: 2
root: /home/lg/ICML2025_project/PUSHPULL_PROJECT/最终的实验/geometric_tmp
使用 PushPull 算法, 这里只记录grad_nrom
直接从第一次 closure() 调用中获取初始值
Initial grad norm: 0.009133534143782325, Initial avg grad norm: 0.0021360095124691725
optimizer初始化成功!
Training Progress:   0%|          | 0/3200 [00:00<?, ?it/s]/home/lg/ICML2025_project/utils/train_utils.py:210: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
Training Progress:   0%|          | 0/3200 [00:04<?, ?it/s, epoch=1, test_accuracy=13.6500%, test_loss=2.2961, train_loss=1.3249]Training Progress:   0%|          | 1/3200 [00:04<3:36:51,  4.07s/it, epoch=1, test_accuracy=13.6500%, test_loss=2.2961, train_loss=1.3249]Training Progress:   0%|          | 1/3200 [00:07<3:36:51,  4.07s/it, epoch=2, test_accuracy=19.9700%, test_loss=2.2894, train_loss=1.3210]Training Progress:   0%|          | 2/3200 [00:07<3:28:10,  3.91s/it, epoch=2, test_accuracy=19.9700%, test_loss=2.2894, train_loss=1.3210]Training Progress:   0%|          | 2/3200 [00:11<3:28:10,  3.91s/it, epoch=3, test_accuracy=25.7300%, test_loss=2.2825, train_loss=1.3160]Training Progress:   0%|          | 3/3200 [00:11<3:25:35,  3.86s/it, epoch=3, test_accuracy=25.7300%, test_loss=2.2825, train_loss=1.3160]Training Progress:   0%|          | 3/3200 [00:15<3:25:35,  3.86s/it, epoch=4, test_accuracy=30.2600%, test_loss=2.2753, train_loss=1.3110]Training Progress:   0%|          | 4/3200 [00:15<3:17:56,  3.72s/it, epoch=4, test_accuracy=30.2600%, test_loss=2.2753, train_loss=1.3110]Training Progress:   0%|          | 4/3200 [00:18<3:17:56,  3.72s/it, epoch=5, test_accuracy=33.6100%, test_loss=2.2674, train_loss=1.3054]Training Progress:   0%|          | 5/3200 [00:18<3:16:05,  3.68s/it, epoch=5, test_accuracy=33.6100%, test_loss=2.2674, train_loss=1.3054]Training Progress:   0%|          | 5/3200 [00:22<3:16:05,  3.68s/it, epoch=6, test_accuracy=35.9400%, test_loss=2.2589, train_loss=1.3000]Training Progress:   0%|          | 6/3200 [00:22<3:16:29,  3.69s/it, epoch=6, test_accuracy=35.9400%, test_loss=2.2589, train_loss=1.3000]Training Progress:   0%|          | 6/3200 [00:26<3:16:29,  3.69s/it, epoch=7, test_accuracy=37.4400%, test_loss=2.2494, train_loss=1.2936]Training Progress:   0%|          | 7/3200 [00:26<3:16:21,  3.69s/it, epoch=7, test_accuracy=37.4400%, test_loss=2.2494, train_loss=1.2936]Training Progress:   0%|          | 7/3200 [00:29<3:16:21,  3.69s/it, epoch=8, test_accuracy=38.2100%, test_loss=2.2388, train_loss=1.2866]Training Progress:   0%|          | 8/3200 [00:29<3:14:48,  3.66s/it, epoch=8, test_accuracy=38.2100%, test_loss=2.2388, train_loss=1.2866]Training Progress:   0%|          | 8/3200 [00:33<3:14:48,  3.66s/it, epoch=9, test_accuracy=38.7200%, test_loss=2.2266, train_loss=1.2785]Training Progress:   0%|          | 9/3200 [00:33<3:12:40,  3.62s/it, epoch=9, test_accuracy=38.7200%, test_loss=2.2266, train_loss=1.2785]Training Progress:   0%|          | 9/3200 [00:36<3:12:40,  3.62s/it, epoch=10, test_accuracy=39.5000%, test_loss=2.2128, train_loss=1.2698]Training Progress:   0%|          | 10/3200 [00:36<3:12:39,  3.62s/it, epoch=10, test_accuracy=39.5000%, test_loss=2.2128, train_loss=1.2698]Training Progress:   0%|          | 10/3200 [00:40<3:12:39,  3.62s/it, epoch=11, test_accuracy=39.7000%, test_loss=2.1967, train_loss=1.2599]Training Progress:   0%|          | 11/3200 [00:40<3:13:14,  3.64s/it, epoch=11, test_accuracy=39.7000%, test_loss=2.1967, train_loss=1.2599]Training Progress:   0%|          | 11/3200 [00:44<3:13:14,  3.64s/it, epoch=12, test_accuracy=40.5600%, test_loss=2.1784, train_loss=1.2489]Training Progress:   0%|          | 12/3200 [00:44<3:13:23,  3.64s/it, epoch=12, test_accuracy=40.5600%, test_loss=2.1784, train_loss=1.2489]Training Progress:   0%|          | 12/3200 [00:48<3:13:23,  3.64s/it, epoch=13, test_accuracy=41.0300%, test_loss=2.1570, train_loss=1.2350]Training Progress:   0%|          | 13/3200 [00:48<3:15:25,  3.68s/it, epoch=13, test_accuracy=41.0300%, test_loss=2.1570, train_loss=1.2350]Training Progress:   0%|          | 13/3200 [00:52<3:15:25,  3.68s/it, epoch=14, test_accuracy=41.5700%, test_loss=2.1323, train_loss=1.2198]Training Progress:   0%|          | 14/3200 [00:52<3:20:17,  3.77s/it, epoch=14, test_accuracy=41.5700%, test_loss=2.1323, train_loss=1.2198]Training Progress:   0%|          | 14/3200 [00:55<3:20:17,  3.77s/it, epoch=15, test_accuracy=42.2200%, test_loss=2.1035, train_loss=1.2023]Training Progress:   0%|          | 15/3200 [00:55<3:22:54,  3.82s/it, epoch=15, test_accuracy=42.2200%, test_loss=2.1035, train_loss=1.2023]Training Progress:   0%|          | 15/3200 [00:59<3:22:54,  3.82s/it, epoch=16, test_accuracy=42.7000%, test_loss=2.0701, train_loss=1.1811]Training Progress:   0%|          | 16/3200 [00:59<3:24:42,  3.86s/it, epoch=16, test_accuracy=42.7000%, test_loss=2.0701, train_loss=1.1811]Training Progress:   0%|          | 16/3200 [01:03<3:24:42,  3.86s/it, epoch=17, test_accuracy=43.4600%, test_loss=2.0316, train_loss=1.1583]Training Progress:   1%|          | 17/3200 [01:03<3:25:16,  3.87s/it, epoch=17, test_accuracy=43.4600%, test_loss=2.0316, train_loss=1.1583]Training Progress:   1%|          | 17/3200 [01:07<3:25:16,  3.87s/it, epoch=18, test_accuracy=44.2200%, test_loss=1.9880, train_loss=1.1319]Training Progress:   1%|          | 18/3200 [01:08<3:30:44,  3.97s/it, epoch=18, test_accuracy=44.2200%, test_loss=1.9880, train_loss=1.1319]Training Progress:   1%|          | 18/3200 [01:12<3:30:44,  3.97s/it, epoch=19, test_accuracy=45.0800%, test_loss=1.9389, train_loss=1.1025]Training Progress:   1%|          | 19/3200 [01:12<3:36:16,  4.08s/it, epoch=19, test_accuracy=45.0800%, test_loss=1.9389, train_loss=1.1025]Training Progress:   1%|          | 19/3200 [01:16<3:36:16,  4.08s/it, epoch=20, test_accuracy=46.3000%, test_loss=1.8847, train_loss=1.0695]Training Progress:   1%|          | 20/3200 [01:16<3:39:21,  4.14s/it, epoch=20, test_accuracy=46.3000%, test_loss=1.8847, train_loss=1.0695]Training Progress:   1%|          | 20/3200 [01:20<3:39:21,  4.14s/it, epoch=21, test_accuracy=47.6300%, test_loss=1.8254, train_loss=1.0332]Training Progress:   1%|          | 21/3200 [01:20<3:40:00,  4.15s/it, epoch=21, test_accuracy=47.6300%, test_loss=1.8254, train_loss=1.0332]Training Progress:   1%|          | 21/3200 [01:24<3:40:00,  4.15s/it, epoch=22, test_accuracy=49.5500%, test_loss=1.7624, train_loss=0.9960]Training Progress:   1%|          | 22/3200 [01:24<3:39:48,  4.15s/it, epoch=22, test_accuracy=49.5500%, test_loss=1.7624, train_loss=0.9960]Training Progress:   1%|          | 22/3200 [01:29<3:39:48,  4.15s/it, epoch=23, test_accuracy=51.1400%, test_loss=1.6965, train_loss=0.9542]Training Progress:   1%|          | 23/3200 [01:29<3:43:07,  4.21s/it, epoch=23, test_accuracy=51.1400%, test_loss=1.6965, train_loss=0.9542]Training Progress:   1%|          | 23/3200 [01:33<3:43:07,  4.21s/it, epoch=24, test_accuracy=53.7700%, test_loss=1.6292, train_loss=0.9151]Training Progress:   1%|          | 24/3200 [01:33<3:44:54,  4.25s/it, epoch=24, test_accuracy=53.7700%, test_loss=1.6292, train_loss=0.9151]