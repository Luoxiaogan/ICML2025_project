nohup: ignoring input
A的第二大特征值: 0.8711614535866962
A的beta: 0.8812264032826911
A的spectral gap: 0.11877359671730892
A的kappa: 3.0439457443122366
S_A是: 142.3316073222403 

(16, 16)
使用异质性数据集
函数内设置种子为: 2
root: /home/lg/ICML2025_project/PUSHPULL_PROJECT/最终的实验/neighbor_tmp
使用 PushPull 算法, 这里只记录grad_nrom
直接从第一次 closure() 调用中获取初始值
Initial grad norm: 0.008442048594588414, Initial avg grad norm: 0.0019713996443897486
optimizer初始化成功!
Training Progress:   0%|          | 0/5000 [00:00<?, ?it/s]/home/lg/ICML2025_project/utils/train_utils.py:210: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=use_amp):
Training Progress:   0%|          | 0/5000 [00:06<?, ?it/s, epoch=1, test_accuracy=20.9000%, test_loss=2.2983, train_loss=1.0274]Training Progress:   0%|          | 1/5000 [00:06<9:01:08,  6.50s/it, epoch=1, test_accuracy=20.9000%, test_loss=2.2983, train_loss=1.0274]Training Progress:   0%|          | 1/5000 [00:12<9:01:08,  6.50s/it, epoch=2, test_accuracy=32.2200%, test_loss=2.2915, train_loss=1.0272]Training Progress:   0%|          | 2/5000 [00:12<8:38:20,  6.22s/it, epoch=2, test_accuracy=32.2200%, test_loss=2.2915, train_loss=1.0272]Training Progress:   0%|          | 2/5000 [00:18<8:38:20,  6.22s/it, epoch=3, test_accuracy=36.0800%, test_loss=2.2846, train_loss=1.0239]Training Progress:   0%|          | 3/5000 [00:18<8:27:47,  6.10s/it, epoch=3, test_accuracy=36.0800%, test_loss=2.2846, train_loss=1.0239]Training Progress:   0%|          | 3/5000 [00:24<8:27:47,  6.10s/it, epoch=4, test_accuracy=37.7400%, test_loss=2.2773, train_loss=1.0201]Training Progress:   0%|          | 4/5000 [00:24<8:16:39,  5.96s/it, epoch=4, test_accuracy=37.7400%, test_loss=2.2773, train_loss=1.0201]Training Progress:   0%|          | 4/5000 [00:30<8:16:39,  5.96s/it, epoch=5, test_accuracy=38.9900%, test_loss=2.2697, train_loss=1.0161]Training Progress:   0%|          | 5/5000 [00:30<8:25:30,  6.07s/it, epoch=5, test_accuracy=38.9900%, test_loss=2.2697, train_loss=1.0161]Training Progress:   0%|          | 5/5000 [00:36<8:25:30,  6.07s/it, epoch=6, test_accuracy=40.1200%, test_loss=2.2616, train_loss=1.0122]Training Progress:   0%|          | 6/5000 [00:36<8:36:33,  6.21s/it, epoch=6, test_accuracy=40.1200%, test_loss=2.2616, train_loss=1.0122]Training Progress:   0%|          | 6/5000 [00:43<8:36:33,  6.21s/it, epoch=7, test_accuracy=40.8700%, test_loss=2.2528, train_loss=1.0076]Training Progress:   0%|          | 7/5000 [00:43<8:45:05,  6.31s/it, epoch=7, test_accuracy=40.8700%, test_loss=2.2528, train_loss=1.0076]Training Progress:   0%|          | 7/5000 [00:49<8:45:05,  6.31s/it, epoch=8, test_accuracy=40.9700%, test_loss=2.2431, train_loss=1.0027]Training Progress:   0%|          | 8/5000 [00:49<8:42:13,  6.28s/it, epoch=8, test_accuracy=40.9700%, test_loss=2.2431, train_loss=1.0027]Training Progress:   0%|          | 8/5000 [00:55<8:42:13,  6.28s/it, epoch=9, test_accuracy=41.1500%, test_loss=2.2326, train_loss=0.9980]Training Progress:   0%|          | 9/5000 [00:55<8:29:44,  6.13s/it, epoch=9, test_accuracy=41.1500%, test_loss=2.2326, train_loss=0.9980]Training Progress:   0%|          | 9/5000 [01:01<8:29:44,  6.13s/it, epoch=10, test_accuracy=41.3700%, test_loss=2.2208, train_loss=0.9921]Training Progress:   0%|          | 10/5000 [01:01<8:32:24,  6.16s/it, epoch=10, test_accuracy=41.3700%, test_loss=2.2208, train_loss=0.9921]Training Progress:   0%|          | 10/5000 [01:08<8:32:24,  6.16s/it, epoch=11, test_accuracy=41.4400%, test_loss=2.2076, train_loss=0.9857]Training Progress:   0%|          | 11/5000 [01:08<8:35:22,  6.20s/it, epoch=11, test_accuracy=41.4400%, test_loss=2.2076, train_loss=0.9857]Training Progress:   0%|          | 11/5000 [01:14<8:35:22,  6.20s/it, epoch=12, test_accuracy=41.4000%, test_loss=2.1926, train_loss=0.9780]Training Progress:   0%|          | 12/5000 [01:14<8:35:53,  6.21s/it, epoch=12, test_accuracy=41.4000%, test_loss=2.1926, train_loss=0.9780]Training Progress:   0%|          | 12/5000 [01:20<8:35:53,  6.21s/it, epoch=13, test_accuracy=41.2700%, test_loss=2.1758, train_loss=0.9707]Training Progress:   0%|          | 13/5000 [01:20<8:35:48,  6.21s/it, epoch=13, test_accuracy=41.2700%, test_loss=2.1758, train_loss=0.9707]Training Progress:   0%|          | 13/5000 [01:26<8:35:48,  6.21s/it, epoch=14, test_accuracy=41.2700%, test_loss=2.1568, train_loss=0.9610]Training Progress:   0%|          | 14/5000 [01:26<8:35:37,  6.20s/it, epoch=14, test_accuracy=41.2700%, test_loss=2.1568, train_loss=0.9610]Training Progress:   0%|          | 14/5000 [01:32<8:35:37,  6.20s/it, epoch=15, test_accuracy=41.2500%, test_loss=2.1351, train_loss=0.9503]Training Progress:   0%|          | 15/5000 [01:32<8:27:52,  6.11s/it, epoch=15, test_accuracy=41.2500%, test_loss=2.1351, train_loss=0.9503]Training Progress:   0%|          | 15/5000 [01:38<8:27:52,  6.11s/it, epoch=16, test_accuracy=41.0700%, test_loss=2.1106, train_loss=0.9399]Training Progress:   0%|          | 16/5000 [01:39<8:36:22,  6.22s/it, epoch=16, test_accuracy=41.0700%, test_loss=2.1106, train_loss=0.9399]Training Progress:   0%|          | 16/5000 [01:44<8:36:22,  6.22s/it, epoch=17, test_accuracy=40.7600%, test_loss=2.0825, train_loss=0.9255]Training Progress:   0%|          | 17/5000 [01:44<8:25:22,  6.09s/it, epoch=17, test_accuracy=40.7600%, test_loss=2.0825, train_loss=0.9255]