{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets/prepare_data.py\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Tuple, List\n",
    "\n",
    "# MNIST transforms\n",
    "\"\"\" MNIST_transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(28, padding=4),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ") \"\"\"\n",
    "\n",
    "MNIST_transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "MNIST_transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# CIFAR-10 transforms\n",
    "cifar10_transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_dataloaders(\n",
    "    n: int, dataset_name: str, batch_size: int, repeat: int = 1\n",
    ") -> Tuple[List[torch.utils.data.DataLoader], torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "\n",
    "    if dataset_name == \"CIFAR10\":\n",
    "        transform_train, transform_test = (\n",
    "            cifar10_transform_train,\n",
    "            cifar10_transform_test,\n",
    "        )\n",
    "        trainset = torchvision.datasets.CIFAR10(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/CIFAR10\",\n",
    "            train=True,\n",
    "            download=False,\n",
    "            transform=transform_train,\n",
    "        )\n",
    "        testset = torchvision.datasets.CIFAR10(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/CIFAR10\",\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=transform_test,\n",
    "        )\n",
    "    elif dataset_name == \"MNIST\":\n",
    "        transform_train, transform_test = MNIST_transform_train, MNIST_transform_test\n",
    "        trainset = torchvision.datasets.MNIST(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/MNIST\",\n",
    "            train=True,\n",
    "            download=False,\n",
    "            transform=transform_train,\n",
    "        )\n",
    "        testset = torchvision.datasets.MNIST(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/MNIST\",\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=transform_test,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "    # Save the original trainset for full_trainloader\n",
    "    original_trainset = trainset\n",
    "\n",
    "    # Repeat the training dataset if repeat > 1\n",
    "    if repeat > 1:\n",
    "        trainset = torch.utils.data.ConcatDataset([trainset] * repeat)\n",
    "\n",
    "    total_train_size = len(trainset)\n",
    "    subset_sizes = [\n",
    "        total_train_size // n + (1 if i < total_train_size % n else 0) for i in range(n)\n",
    "    ]\n",
    "\n",
    "    subsets = torch.utils.data.random_split(trainset, subset_sizes, generator=generator)\n",
    "\n",
    "    trainloader_list = [\n",
    "        torch.utils.data.DataLoader(\n",
    "            subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            prefetch_factor=2,\n",
    "            persistent_workers=True,\n",
    "            generator=generator,\n",
    "        )\n",
    "        for subset in subsets\n",
    "    ]\n",
    "\n",
    "    # Create a DataLoader for the full training set using the original trainset\n",
    "    full_trainloader = torch.utils.data.DataLoader(\n",
    "        original_trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "        generator=generator,\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=100,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "        generator=generator,\n",
    "    )\n",
    "\n",
    "    return trainloader_list, testloader, full_trainloader\n",
    "\n",
    "\n",
    "def get_dataloaders_high_hetero(\n",
    "    n: int, dataset_name: str, batch_size: int, repeat: int = 1\n",
    ") -> Tuple[List[torch.utils.data.DataLoader], torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "\n",
    "    # Load dataset\n",
    "    if dataset_name == \"CIFAR10\":\n",
    "        transform_train, transform_test = (\n",
    "            cifar10_transform_train,\n",
    "            cifar10_transform_test,\n",
    "        )\n",
    "        trainset = torchvision.datasets.CIFAR10(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/CIFAR10\",\n",
    "            train=True,\n",
    "            download=False,\n",
    "            transform=transform_train,\n",
    "        )\n",
    "        testset = torchvision.datasets.CIFAR10(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/CIFAR10\",\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=transform_test,\n",
    "        )\n",
    "        num_classes = 10\n",
    "    elif dataset_name == \"MNIST\":\n",
    "        transform_train, transform_test = MNIST_transform_train, MNIST_transform_test\n",
    "        trainset = torchvision.datasets.MNIST(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/MNIST\",\n",
    "            train=True,\n",
    "            download=False,\n",
    "            transform=transform_train,\n",
    "        )\n",
    "        testset = torchvision.datasets.MNIST(\n",
    "            root=\"/root/GanLuo/ICML2025_project/data/raw/MNIST\",\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=transform_test,\n",
    "        )\n",
    "        num_classes = 10\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "    # Save original trainset for full_trainloader\n",
    "    original_trainset = trainset\n",
    "\n",
    "    # Repeat the training dataset if repeat > 1\n",
    "    if repeat > 1:\n",
    "        trainset = torch.utils.data.ConcatDataset([trainset] * repeat)\n",
    "\n",
    "    # Get labels and create class-specific indices\n",
    "    labels = np.array(trainset.targets)\n",
    "    class_indices = [np.where(labels == i)[0] for i in range(num_classes)]\n",
    "\n",
    "    # Create heterogeneous distributions for each node\n",
    "    subsets = []\n",
    "    total_size = len(trainset)\n",
    "    base_size = total_size // n\n",
    "    \n",
    "    # Generate Dirichlet distribution for class proportions across nodes\n",
    "    alpha = 0.5  # Lower alpha means higher heterogeneity\n",
    "    class_dist = np.random.dirichlet([alpha] * n, num_classes)\n",
    "    \n",
    "    # Assign samples to each node\n",
    "    for node in range(n):\n",
    "        node_indices = []\n",
    "        node_size = base_size + (1 if node < total_size % n else 0)\n",
    "        \n",
    "        # Calculate target number of samples per class for this node\n",
    "        target_dist = class_dist[:, node] * node_size\n",
    "        \n",
    "        for cls in range(num_classes):\n",
    "            num_samples = int(target_dist[cls])\n",
    "            available_indices = class_indices[cls]\n",
    "            \n",
    "            if len(available_indices) > 0:\n",
    "                selected = np.random.choice(\n",
    "                    available_indices,\n",
    "                    size=min(num_samples, len(available_indices)),\n",
    "                    replace=False\n",
    "                )\n",
    "                node_indices.extend(selected)\n",
    "                # Remove used indices\n",
    "                class_indices[cls] = np.setdiff1d(class_indices[cls], selected)\n",
    "                \n",
    "        subsets.append(torch.utils.data.Subset(trainset, node_indices))\n",
    "\n",
    "    # Create DataLoaders for each subset\n",
    "    trainloader_list = [\n",
    "        torch.utils.data.DataLoader(\n",
    "            subset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            prefetch_factor=2,\n",
    "            persistent_workers=True,\n",
    "            generator=generator,\n",
    "        )\n",
    "        for subset in subsets\n",
    "    ]\n",
    "\n",
    "    # Full training set DataLoader\n",
    "    full_trainloader = torch.utils.data.DataLoader(\n",
    "        original_trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "        generator=generator,\n",
    "    )\n",
    "\n",
    "    # Test set DataLoader\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=100,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "        generator=generator,\n",
    "    )\n",
    "\n",
    "    return trainloader_list, testloader, full_trainloader\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_heatmap(trainloader_list, num_classes=10):\n",
    "    num_nodes = len(trainloader_list)\n",
    "    class_counts = np.zeros((num_nodes, num_classes))\n",
    "\n",
    "    # 统计类别分布\n",
    "    for node_idx, loader in enumerate(trainloader_list):\n",
    "        for _, labels in loader:\n",
    "            for cls in range(num_classes):\n",
    "                class_counts[node_idx, cls] += (labels == cls).sum().item()\n",
    "\n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(class_counts, annot=True, fmt='.0f', cmap='YlOrRd')\n",
    "    plt.xlabel('类别')\n",
    "    plt.ylabel('节点')\n",
    "    plt.title('类别分布热力图')\n",
    "    plt.show()\n",
    "\n",
    "# 调用示例\n",
    "# visualize_heatmap(trainloader_list)\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def visualize_kl_divergence(trainloader_list, num_classes=10):\n",
    "    num_nodes = len(trainloader_list)\n",
    "    class_counts = np.zeros((num_nodes, num_classes))\n",
    "\n",
    "    # 统计类别分布\n",
    "    for node_idx, loader in enumerate(trainloader_list):\n",
    "        for _, labels in loader:\n",
    "            for cls in range(num_classes):\n",
    "                class_counts[node_idx, cls] += (labels == cls).sum().item()\n",
    "\n",
    "    # 计算比例\n",
    "    class_ratios = class_counts / class_counts.sum(axis=1, keepdims=True)\n",
    "    mean_dist = class_ratios.mean(axis=0)  # 平均分布\n",
    "\n",
    "    # 计算KL散度\n",
    "    kl_divs = [entropy(class_ratios[i], mean_dist) for i in range(num_nodes)]\n",
    "\n",
    "    # 绘制\n",
    "    plt.bar(range(num_nodes), kl_divs)\n",
    "    plt.xticks(range(num_nodes), [f'节点 {i+1}' for i in range(num_nodes)])\n",
    "    plt.ylabel('KL散度')\n",
    "    plt.title('各节点与平均分布的异质性')\n",
    "    plt.show()\n",
    "\n",
    "# 调用示例\n",
    "# visualize_kl_divergence(trainloader_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      4\u001b[0m repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m trainloader_list, testloader, full_trainloader \u001b[38;5;241m=\u001b[39m get_dataloaders(n, dataset_name, batch_size, repeat)\n\u001b[1;32m      7\u001b[0m visualize_heatmap(trainloader_list)\n\u001b[1;32m      8\u001b[0m visualize_kl_divergence(trainloader_list)\n",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m, in \u001b[0;36mget_dataloaders\u001b[0;34m(n, dataset_name, batch_size, repeat)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     85\u001b[0m     transform_train, transform_test \u001b[38;5;241m=\u001b[39m MNIST_transform_train, MNIST_transform_test\n\u001b[0;32m---> 86\u001b[0m     trainset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(\n\u001b[1;32m     87\u001b[0m         root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/GanLuo/ICML2025_project/data/raw/MNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     89\u001b[0m         download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     90\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform_train,\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     92\u001b[0m     testset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(\n\u001b[1;32m     93\u001b[0m         root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/GanLuo/ICML2025_project/data/raw/MNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m         train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m         download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     96\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform_test,\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchvision/datasets/mnist.py:103\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_data()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "n = 16\n",
    "dataset_name = \"MNIST\"\n",
    "batch_size = 128\n",
    "repeat = 1\n",
    "\n",
    "trainloader_list, testloader, full_trainloader = get_dataloaders(n, dataset_name, batch_size, repeat)\n",
    "visualize_heatmap(trainloader_list)\n",
    "visualize_kl_divergence(trainloader_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
