epoch,train_loss(total)
1,2.280776383280754
2,2.167153985500336
3,2.102302150130272
4,2.0372149941325186
5,2.036995073854923
6,1.9638762617111205
7,1.9275736910104753
8,1.8711877927184104
9,1.9438677355647087
10,1.8647057238221167
11,1.8243261101841926
12,1.8216144409775734
13,1.7833359548449517
14,1.7718925347924233
15,1.733233227431774
16,1.7765313124656676
17,1.7109358578920364
18,1.6683641502261162
19,1.6588858211040496
20,1.6726695892214776
21,1.696678156554699
22,1.6156150749325753
23,1.5649945685267448
24,1.5365161147713662
25,1.5677876442670822
26,1.5522890436649321
27,1.5901562514901162
28,1.52387366771698
29,1.4858444079756736
30,1.451037047803402
31,1.4725116649270058
32,1.4275829276442529
33,1.429529459476471
34,1.433717240691185
35,1.4618359592556953
36,1.3801773229241372
37,1.3475339403748512
38,1.3423542335629464
39,1.35007261171937
40,1.336348705291748
41,1.3042100167274475
42,1.3219996705651282
43,1.2607005840539933
44,1.2895867690443992
45,1.2587430900335312
46,1.2321751354634762
47,1.2567139501869677
48,1.229990804195404
